diff --git a/node_modules/markdown-it/lib/parser_inline.js b/node_modules/markdown-it/lib/parser_inline.js
index c8e66d3..b5e9489 100644
--- a/node_modules/markdown-it/lib/parser_inline.js
+++ b/node_modules/markdown-it/lib/parser_inline.js
@@ -18,6 +18,7 @@ var _rules = [
   [ 'escape',          require('./rules_inline/escape') ],
   [ 'backticks',       require('./rules_inline/backticks') ],
   [ 'strikethrough',   require('./rules_inline/strikethrough').tokenize ],
+  [ 'increase_size',   require('./rules_inline/increase_size').tokenize ],
   [ 'emphasis',        require('./rules_inline/emphasis').tokenize ],
   [ 'link',            require('./rules_inline/link') ],
   [ 'image',           require('./rules_inline/image') ],
@@ -29,6 +30,7 @@ var _rules = [
 var _rules2 = [
   [ 'balance_pairs',   require('./rules_inline/balance_pairs') ],
   [ 'strikethrough',   require('./rules_inline/strikethrough').postProcess ],
+  [ 'increase_size',   require('./rules_inline/increase_size').postProcess ],
   [ 'emphasis',        require('./rules_inline/emphasis').postProcess ],
   [ 'text_collapse',   require('./rules_inline/text_collapse') ]
 ];
diff --git a/node_modules/markdown-it/lib/rules_inline/increase_size.js b/node_modules/markdown-it/lib/rules_inline/increase_size.js
new file mode 100644
index 0000000..32120a7
--- /dev/null
+++ b/node_modules/markdown-it/lib/rules_inline/increase_size.js
@@ -0,0 +1,115 @@
+// &&increase size&&
+'use strict';
+
+module.exports.tokenize = function increase_size(state, silent) {
+    var i, scanned, token, len, ch,
+        start = state.pos,
+        marker = state.src.charCodeAt(start);
+
+    if (silent) { return false; }
+
+    if (marker !== 0x26/* & */) { return false; }
+
+    scanned = state.scanDelims(state.pos, true);
+    len = scanned.length;
+    ch = String.fromCharCode(marker);
+
+    if (len < 2) { return false; }
+
+    if (len % 2) {
+        token         = state.push('text', '', 0);
+        token.content = ch;
+        len--;
+    }
+
+    for (i = 0; i < len; i += 2) {
+        token         = state.push('text', '', 0);
+        token.content = ch + ch;
+    
+        state.delimiters.push({
+            marker: marker,
+            length: 0,     // disable "rule of 3" length checks meant for emphasis
+            token:  state.tokens.length - 1,
+            end:    -1,
+            open:   scanned.can_open,
+            close:  scanned.can_close
+        });
+    }
+
+    state.pos += scanned.length;
+    return true
+};
+
+function postProcess(state, delimiters) {
+    var i, j,
+      startDelim,
+      endDelim,
+      token,
+      loneMarkers = [],
+      max = delimiters.length;
+
+    for (i = 0; i < max; i++) {
+        startDelim = delimiters[i];
+
+        if (startDelim.marker !== 0x26/* & */) { 
+            continue; 
+        }
+
+        if (startDelim.end === -1) {
+            continue;
+        }
+      
+        endDelim = delimiters[startDelim.end];
+
+        token         = state.tokens[startDelim.token];
+        token.type    = 's_open';
+        token.tag     = 's';
+        token.nesting = 1;
+        token.markup  = '&&';
+        token.content = '';
+
+        token         = state.tokens[endDelim.token];
+        token.type    = 's_close';
+        token.tag     = 's';
+        token.nesting = -1;
+        token.markup  = '&&';
+        token.content = '';
+
+        if (state.tokens[endDelim.token - 1].type === 'text' &&
+            state.tokens[endDelim.token - 1].content === '&') {
+
+            loneMarkers.push(endDelim.token - 1);
+        }
+    }
+
+    while (loneMarkers.length) {
+        i = loneMarkers.pop();
+        j = i + 1;
+    
+        while (j < state.tokens.length && state.tokens[j].type === 's_close') {
+            j++;
+        }
+    
+        j--;
+    
+        if (i !== j) {
+            token = state.tokens[j];
+            state.tokens[j] = state.tokens[i];
+            state.tokens[i] = token;
+        }
+    }
+};
+
+module.exports.postProcess = function increase_size(state) {
+    var curr,
+        tokens_meta = state.tokens_meta,
+        max = state.tokens_meta.length;
+  
+    postProcess(state, state.delimiters);
+  
+    for (curr = 0; curr < max; curr++) {
+        if (tokens_meta[curr] && tokens_meta[curr].delimiters) {
+             postProcess(state, tokens_meta[curr].delimiters);
+        }
+    }
+};
\ No newline at end of file
